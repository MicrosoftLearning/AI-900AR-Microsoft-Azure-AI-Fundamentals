{  
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# تصنيف الصورة\r\n",
        "\r\n",
        "توفر خدمة *الرؤية الحاسوبية* المعرفية نماذج مفيدة مثبتة مسبقًا للعمل مع الصور، ولكنك ستحتاج غالبًا إلى تدريب نموذجك الخاص على الرؤية الخاصة بالحاسوب. على سبيل المثال، لنفترض أن شركة البيع بالتجزئة Northwind Traders تريد إنشاء نظام دفع آلي يحدد عناصر البقالة التي يرغب العملاء في شرائها استنادًا إلى صورة التقطتها الكاميرا عند الخروج. للقيام بذلك، ستحتاج إلى تدريب نموذج تصنيف يمكنه تصنيف الصور لتحديد العنصر الذي يتم شراؤه.\r\n",
        "\r\n",
        "![روبوت يحمل حافظة أوراق، يصنف صور تفاحة وموزة وبرتقالة](./images/image-classification.jpg)\r\n",
        "\r\n",
        "في Azure، يمكنك استخدام خدمة ***الرؤية المعدلة*** المعرفية لتدريب نموذج تصنيف الصور استنادًا إلى الصور الموجودة. ثمة عنصران لإنشاء برنامج تصنيف الصور. أولًا، يجب تدريب نموذج للتعرف على الفئات المختلفة باستخدام الصور الموجودة. بعد ذلك، عندما يتم تدريب النموذج، يجب عليك نشره كخدمة يمكن استخدامها من قبل التطبيقات.\r\n",
        "\r\n",
        "## إنشاء مورد رؤية معدلة\r\n",
        "\r\n",
        "لاستخدام خدمة رؤية معدلة، تحتاج إلى مورد Azure يمكنك استخدامه *لتدريب* نموذج، ومورد يمكنك *نشره* لتستخدمه التطبيقات. يمكن أن يكون المورد لأي من المهمتين (أو لكليهما) مورد **خدمات معرفية** عام، أو مورد **رؤية معدلة** محدد. يمكنك استخدام نفس مورد الخدمات المعرفية لكل مهمة من هذه المهام، أو يمكنك استخدام موارد مختلفة (في نفس المنطقة) لكل مهمة لإدارة التكاليف بشكل منفصل.\r\n",
        "\r\n",
        "استخدم الأمر التالي لإنشاء مورد **رؤية معدلة** جديدة:\r\n",
        "\r\n",
        "1. في مستعرضٍ جديدٍ، افتح مدخل Azure على [https://portal.azure.com](https://portal.azure.com)، وقم بتسجيل الدخول باستخدام حساب Microsoft المرتبط باشتراك Azure الخاص بك.\r\n",
        "2. اضغط على زر **&#65291; إنشاء مورد**، ابحث عن *رؤية معدلة، *وأنشئ مورد **رؤية معدلة** بالإعدادات التالية:\r\n",
        "    - **إنشاء الخيارات**: كلاهما\r\n",
        "    - **الاشتراك**: *اشتراكك في Azure*\r\n",
        "    - **مجموعة الموارد**: *حدد أو أنشئ مجموعة موارد باسمٍ فريدٍ*\r\n",
        "    - **الاسم**: *أدخل اسمًا فريدًا*.\r\n",
        "    - **موقع التدريب**: *اختر أي منطقة متوفرة*\r\n",
        "    - **مستوى أسعار التدريب:** F0\r\n",
        "    - **موقع التنبؤ:** *نفس المنطقة التي يوجد بها مورد التدريب*\r\n",
        "    - **مستوى أسعار التنبؤ:** F0\r\n",
        "\r\n",
        "    >**ملاحظة**: إذا كانت لديك خدمة رؤية معدلة F0 في اشتراكك مسبقًا، فاختر **S0 ** لأجل هذا.\r\n",
        "\r\n",
        "3. انتظر حتى يتم إنشاء الموارد، ولاحظ أنه يتم توفير اثنين من موارد الرؤية المعدلة، بحيث يكون ثمة واحد للتدريب والآخر للتنبؤ. يمكنك عرض هذا من خلال الانتقال إلى مجموعة الموارد حيث قمت بإنشائها.\r\n",
        "\r\n",
        "## قم بإنشاء مشروع رؤية مخصصة\r\n",
        "\r\n",
        "لتدريب نموذج الكشف عن الأشياء، تحتاج إلى إنشاء مشروع رؤية معدلة بناءً على مورد التدريب الخاص بك. للقيام بذلك، ستستخدم منصة الرؤية المعدلة Custom Vision.\r\n",
        "\r\n",
        "1. قم بتنزيل واستخراج صور التدريب من https://aka.ms/fruit-images.\r\n",
        "2. في علامة تبويب مستعرض أخرى، افتح مدخل رؤية معدلة على [https://customvision.ai.](https://customvision.ai) إذا طُلب منك ذلك، قم بتسجيل الدخول باستخدام حساب Microsoft المرتبط باشتراك Azure الخاص بك، ووافق على شروط الخدمة.\r\n",
        "3. في مدخل الرؤية المعدلة، قم بإنشاء مشروع جديد عبر الإعدادات التالية:\r\n",
        "    - **الاسم:** السحب في البقالة\r\n",
        "    - **الوصف**: تصنيف الصورة لمحلات البقالة\r\n",
        "    - **المورد** *مورد الرؤية المعدلة الذي أنشأته مسبقًا*\r\n",
        "    - **أنواع المشاريع:** تصنيف\r\n",
        "    - **أنواع التصنيف:** متعدد الفئات (تمييز واحد لكل صورة)\r\n",
        "    - **المجالات**: الطعام\r\n",
        "4. انقر فوق** \\ + \\] [إضافة صور**، واختر كافة المجلد الموجودة في ملف **التفاح** الذي قمت باستخراجه مسبقًا. ثم قم بتحميل ملفات الصور، مع تحديد تمييز *التفاحة*، كالتالي:\r\n",
        "\r\n",
        "![تحميل التفاح مع علامة التعريف الخاصة بالتفاح](./images/upload_apples.jpg)\r\n",
        "   \r\n",
        "5. كرر الخطوة السابقة لتحميل الصور في مجلد **الموز **مع تمييز *الموز*، والصور الموجودة في ملف **البرتقال** مع تمييز *البرتقال*.\r\n",
        "6. اطلع على الصور التي قمت بتحميلها في مشروع الرؤية المعدلة Custom Vision - يجب أن يكون هناك 15 صورة لكل فصل، وذلك على النحو التالي:\r\n",
        "\r\n",
        "![صور مميزة للفواكه - 15 تفاحة و 15 موزة و 15 برتقالة](./images/fruit.jpg)\r\n",
        "    \r\n",
        "7. في مشروع الرؤية المعدلة Custom Vision، فوق الصور، انقر فوق **زر التدريب** لتدريب نموذج تصنيفٍ باستخدام الصور المميزة. اختر خيار **التدريب السريع**، ثم انتظر حتى يكتمل تكرار التدريب (قد يستغرق ذلك دقيقة أو نحو ذلك).\r\n",
        "8. عندما يتم التدريب على دورة النموذج المتكررة، قم بمراجعة مقاييس أداء *الدقة* *والاستدعاء* و *AP* - والتي تقيس دقة التنبؤ لنموذج التصنيف، ويجب أن تكون جميعها عالية.\r\n",
        "\r\n",
        "## تختبار النموذج\r\n",
        "\r\n",
        "قبل نشر هذه الدورة المتكررة الخاصة بالنموذج لتستخدمه التطبيقات، فإنه يجب عليك اختباره.\r\n",
        "\r\n",
        "1. فوق مقاييس الأداء، انقر على **اختبار سريع**.\r\n",
        "2. في مربع عنوان **URL للصورة**، اكتب `https://aka.ms/apple-image` وانقر فوق &#10132;\r\n",
        "3. اعرض التنبؤات التي أعادها نموذجك - يجب أن تكون درجة احتمالية *التفاح* هي الأعلى، كما يلي:\r\n",
        "\r\n",
        "![صورة مع التنبؤ التصنيفي للتفاح](./images/test-apple.jpg)\r\n",
        "\r\n",
        "4. أغلق نافذة **الاختبار السريع**.\r\n",
        "\r\n",
        "## أنشر واستعمل نموذج تصنيف الصور\r\n",
        "\r\n",
        "أنت الآن جاهز لنشر نموذجك المدرّب واستخدامه من تطبيق عميل.\r\n",
        "\r\n",
        "9. انقر فوق **&#128504; انشر **لنشر النموذج المدرب بالإعدادات التالية:\r\n",
        "    - **اسم النموذج**: البقالة\r\n",
        "    - **مورد التنبؤ**: *مورد التنبؤ الذي قمت بإنشائه مسبقًا*.\r\n",
        "\r\n",
        "### (!) تسجيل الوصول \r\n",
        "هل استخدمت نفس اسم النموذج: **البقالة**؟   \r\n",
        "\r\n",
        "10. بعد النشر، انقر فوق أيقونة* الإعدادات* (&#9881;) في أعلى يمين صفحة **الأداء** لعرض إعدادات المشروع. بعد ذلك، تحت **\"عام\"** (على اليسار)، انسخ **رقم تعريف المشروع**. انتقل أسفل الصفحة وقم بلصقه في خلية الرمز أسفل الخطوة 13 **لتحل محل YOUR_PROJECT_ID.**\r\n",
        "\r\n",
        "![معرف المشروع في إعدادات المشروع](./images/cv_project_settings.jpg)\r\n",
        "\r\n",
        "> _**تنبيه:** إذا استخدمت مورد **الخدمات المعرفية** بدلًا من إنشاء مورد **رؤية معدلة** في بداية هذا التمرين، فيمكنك نسخ مفتاحه ونقطة نهايته من الجانب الأيمن من إعدادات المشروع، ولصقه في خانة التعليمات البرمجية أدناه، وتشغيله لرؤية نتائجه. خلافًا لذلك، تابع إكمال الخطوات أدناه للحصول على المفتاح ونقطة النهاية لمورد توقع الرؤية المخصصة.\r\n",
        "\r\n",
        "11. في الجزء العلوي الأيسر من صفحة **إعدادات المشروع**، انقر فوق أيقونة *معرض المشاريع* (&#128065;) للعودة إلى الصفحة الرئيسية لمنصة الرؤية المعدلة Custom Vision، حيث يتم إدراج مشروعك الآن.\r\n",
        "\r\n",
        "12. في الصفحة الرئيسية لمنصة الرؤية المعدلة، في أعلى اليمين، انقر فوق رمز *الإعدادات *(&#9881;) لعرض إعدادات خدمة الرؤية المعدلة الخاصة بك. بعد ذلك، تحت **الموارد،** قم بتوسيع مورد **التنبؤ** الخاص بك ( <u>وليس</u>مورد التدريب) وانسخ قيم **المفتاح** و**نقطة النهاية** الخاصة به إلى خانة الرمز أسفل الخطوة 13، مع استبدال **YOUR_KEY** و **YOUR_ENDPOINT**.\r\n",
        "\r\n",
        "### (!) تسجيل الوصول \r\n",
        "إذا كنت تستخدم مورد **رؤية معدلة**، فهل استخدمت مورد **التنبؤ** (<u>وليس</u> مورد التدريب)؟\r\n",
        "\r\n",
        "![مفتاح مورد التنبؤ ونقطة النهاية في إعدادات الرؤية المعدلة](./images/cv_settings.jpg)\r\n",
        "\r\n",
        "13. قم بتشغيل خانة التعليمات البرمجية أدناه بالنقر فوق زر **تشغيل الخانة** (&#9655;) (على يسار الخلية) لتعيين المتغيرات على رقم تعيين المشروع والمفتاح ونقطة النهاية."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "project_id = 'YOUR_PROJECT_ID'\n",
        "cv_key = 'YOUR_KEY'\n",
        "cv_endpoint = 'YOUR_ENDPOINT'\n",
        "\n",
        "model_name = 'groceries' # this must match the model name you set when publishing your model iteration (it's case-sensitive)!\n",
        "print('Ready to predict using model {} in project {}'.format(model_name, project_id))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599691949340
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "يمكنك الآن استخدام المفتاح ونقطة النهاية مع عميل رؤية معدلة للاتصال بنموذج تصنيف الرؤية المعدلة الخاص بك.\r\n",
        "\r\n",
        "قم بتشغيل خانة التعليمات البرمجية التالية، لتصنيف مجموعة مختارة من صور الاختبار باستخدام النموذج المنشور.\r\n",
        "\r\n",
        "> **ملاحظة**: لا تقلق كثيرًا بشأن تفاصيل الكود. يستخدم Computer Vision SDK لـ Python للحصول على تنبؤ بالفئة لكل صورة في مجلد / data / image-rating / test-fruit."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient\n",
        "from msrest.authentication import ApiKeyCredentials\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import os\n",
        "%matplotlib inline\n",
        "\n",
        "# احصل على صور الاختبار من مجلد البيانات / الرؤية / الاختبار.\r\n",
        "test_folder = os.path.join('data', 'image-classification', 'test-fruit')\n",
        "test_images = os.listdir(test_folder)\n",
        "\n",
        "# إنشاء مثيل لخدمة التنبؤ\r\n",
        "credentials = ApiKeyCredentials(in_headers={\"Prediction-key\": cv_key})\n",
        "custom_vision_client = CustomVisionPredictionClient(endpoint=cv_endpoint, credentials=credentials)\n",
        "\n",
        "# إنشاء شكل لعرض النتائج\r\n",
        "fig = plt.figure(figsize=(16, 8))\n",
        "\n",
        "# احصل على الصور، وأظهر الفئات التنبؤية لكل منها\r\n",
        "print('Classifying images in {} ...'.format(test_folder))\n",
        "for i in range(len(test_images)):\n",
        "    # Open the image, and use the custom vision model to classify it\n",
        "    image_contents = open(os.path.join(test_folder, test_images[i]), \"rb\")\n",
        "    classification = custom_vision_client.classify_image(project_id, model_name, image_contents.read())\n",
        "    # The results include a prediction for each tag, in descending order of probability - get the first one\n",
        "    prediction = classification.predictions[0].tag_name\n",
        "    # Display the image with its predicted class\n",
        "    img = Image.open(os.path.join(test_folder, test_images[i]))\n",
        "    a=fig.add_subplot(len(test_images)/3, 3,i+1)\n",
        "    a.axis('off')\n",
        "    imgplot = plt.imshow(img)\n",
        "    a.set_title(prediction)\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599692327514
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "نأمل أن يكون نموذج تصنيف الصور الخاص بك قد حدد بشكل صحيح عناصر البقالة في الصور.\r\n",
        "\r\n",
        "## معرفة المزيد\r\n",
        "\r\n",
        "تعرضُ خدمة الرؤية المعدلة Custom Vision إمكانيات أكثر مما اكتشفناه في هذا التمرين. على سبيل المثال، يمكنك أيضًا استخدام خدمة الرؤية المعدلة لإنشاء *نماذج للكشف عن الأشياء*، التي لا تصنف الأشياء في الصور فحسب، بل تحدد أيضًا *المربعات المحيطة* التي تعرض موقع الشيء في الصورة.\r\n",
        "\r\n",
        "لمعرفة المزيد حول خدمة الرؤية المعدلة المعرفية، [راجع مستندات الرؤية المعدلة](https://docs.microsoft.com/azure/cognitive-services/custom-vision-service/home)."
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
 }
