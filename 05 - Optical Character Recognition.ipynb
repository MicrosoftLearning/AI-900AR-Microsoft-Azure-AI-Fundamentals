{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# تعرّف بصري على الحروف\r\n",
        "\r\n",
        "![روبوت يقرأ جريدة](./images/ocr.jpg)\r\n",
        "\r\n",
        "يتمثل أحد التحديات الشائعة في الرؤية الخاصة بالكمبيوتر في اكتشاف النص في صورة ما وتفسيره. غالبًا ما يشار إلى هذا النوع من المعالجة *بالتعرف على الأحرف *(OCR).\r\n",
        "\r\n",
        "## استخدم خدمة الرؤية الخاصة بالكمبيوتر للبحث عن نصٍ في الصورة\r\n",
        "\r\n",
        "توفر خدمة **الرؤية الحاسوبية المعرفية** دعمًا لمهام التعرف على الحروف، بما في ذلك:\r\n",
        "\r\n",
        "- واجهة برمجة تطبيقات **OCR** التي يمكنك استخدامها لقراءة النص بلغات متعددة. يمكن استخدام واجهة برمجة التطبيقات هذه بشكل متزامن، وتعمل بشكل جيد عندما تحتاج إلى اكتشاف وقراءة جزء صغير من النص في صورة.\r\n",
        "- واجهة برمجة تطبيقات **للقراءة **مُحسَّنة لقراءة المستندات الأكبر حجمًا. يتم استخدام واجهة برمجة التطبيقات هذه بشكل غير متزامن، ويمكن استخدامها لكل من النصوص المطبوعة والمكتوبة بخط اليد.\r\n",
        "\r\n",
        "يمكنك استخدام هذه الخدمة عن طريق إنشاء إما مورد **رؤية حاسوبية** أو مورد **خدمات معرفية.**\r\n",
        "\r\n",
        "إذا لم تكن قد قمت بذلك من قبل، قم بإنشاء مورد **خدمات معرفية** ضمن اشتراك Azure الخاص بك.\r\n",
        "\r\n",
        "> **ملاحظة**: إذا كان لديك بالفعل مورد خدمات معرفية، فقط افتح صفحة **البدء السريع** الخاصة به في منصة Azure وانسخ مفتاحه ونقطة النهاية إلى الخلية أدناه. خلاف ذلك، اتبع الخطوات أدناه لإنشاء واحدة.\r\n",
        "\r\n",
        "1. في علامة تبويب مستعرض أخرى، افتح مدخل Azure على https://portal.azure.com، وقم بتسجيل الدخول باستخدام حساب Microsoft الخاص بك.\r\n",
        "\r\n",
        "2. انقر فوق** زر إنشاء **&#65291; *مورد 65291، وابحث عن *خدمات معرفية**، وأنشئ مورد **خدمات معرفية بالإعدادات التالية:\r\n",
        "    - **الاشتراك**: *اشتراكك في Azure.*\r\n",
        "    - **مجموعة الموارد**: *حدد أو أنشئ مجموعة موارد باسم فريد*.\r\n",
        "    - **المنطقة**. *اختر أي منطقة متوفرة*:\r\n",
        "    - **الاسم**: *أدخل اسمًا فريدًا*.\r\n",
        "    - **مستوى الأسعار**: S0\r\n",
        "    - **أؤكد أنني قد قرأت وفهمت الإخطارات**: تم الاختيار.\r\n",
        "3. انتظر حتى اكتمال النشر. ثم انتقل إلى مورد الخدمات المعرفية الخاص بك، وفي صفحة **نظرة عامة**، انقر على رابط لإدارة مفاتيح الخدمة. ستحتاج إلى نقطة النهاية والمفاتيح للاتصال بمورد الخدمات المعرفية من تطبيقات العميل.\r\n",
        "\r\n",
        "### احصل على المفتاح ونقطة النهاية لمورد الخدمات المعرفية\r\n",
        "\r\n",
        "لاستخدام موارد الخدمات المعرفية، تحتاج تطبيقات العميل إلى نقطة النهاية ومفتاح المصادقة:\r\n",
        "\r\n",
        "1. في مدخل Azure، في صفحة **المفاتيح ونقطة النهاية** لمورد الخدمة المعرفية، انسخ **Key1** لموردك وقم بلصقه في الرمز أدناه، مع استبدال **YOUR_COG_KEY**.\r\n",
        "2. انسخ **نقطة النهاية** لموردك وألصقها في الرمز أدناه، لتحل محل **YOUR_COG_ENDPOINT**.\r\n",
        "3. قم بتشغيل الكود في الخلية أدناه بالنقر فوق الزر **تشغيل الخانة** (&#9655;) (على يسار الخانة)."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "cog_key = 'YOUR_COG_KEY'\n",
        "cog_endpoint = 'YOUR_COG_ENDPOINT'\n",
        "\n",
        "print('Ready to use cognitive services at {} using key {}'.format(cog_endpoint, cog_key))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599694246277
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "الآن بعد أن قمت بإعداد المفتاح ونقطة النهاية، يمكنك استخدام مورد خدمة رؤية خاصةٍ بالكمبيوتر، وذلك لاستخراج نص من صورة.\r\n",
        "\r\n",
        "لنبدأ بواجهة برمجة تطبيقات **التعرف على الحروف،** والتي تمكنك من تحليل صورة ما بشكل متزامن وقراءة أي نص تحتوي عليه. في هذه الحالة، لديك صورة إرشادية لشركة البيع بالتجزئة الخيالية Northwind Traders التي تتضمن بعض النصوص. قم بتشغيل الخلية أدناه لقراءتها.. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
        "from msrest.authentication import CognitiveServicesCredentials\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageDraw\n",
        "import os\n",
        "%matplotlib inline\n",
        "\n",
        "# احصل على عميل لخدمة الرؤية الخاصة بالكمبيوتر\r\n",
        "computervision_client = ComputerVisionClient(cog_endpoint, CognitiveServicesCredentials(cog_key))\n",
        "\n",
        "# اقرأ ملف الصورة\r\n",
        "image_path = os.path.join('data', 'ocr', 'advert.jpg')\n",
        "image_stream = open(image_path, \"rb\")\n",
        "\n",
        "# استخدم خدمة الرؤية الخاصة بالكمبيوتر للبحث عن نص في الصورة\r\n",
        "read_results = computervision_client.recognize_printed_text_in_stream(image_stream)\n",
        "\n",
        "# معالجة النص سطرًا بسطرٍ\r\n",
        "for region in read_results.regions:\n",
        "    for line in region.lines:\n",
        "\n",
        "        # Read the words in the line of text\n",
        "        line_text = ''\n",
        "        for word in line.words:\n",
        "            line_text += word.text + ' '\n",
        "        print(line_text.rstrip())\n",
        "\n",
        "# افتح الصورة لعرضها.\r\n",
        "fig = plt.figure(figsize=(7, 7))\n",
        "img = Image.open(image_path)\n",
        "draw = ImageDraw.Draw(img)\n",
        "plt.axis('off')\n",
        "plt.imshow(img)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599694257280
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "تم تنظيم النص الموجود في الصورة في هيكل هرمي للمناطق والخطوط والكلمات، ويقرأها الرمز لاسترداد النتائج.\r\n",
        "\r\n",
        "في النتائج، اعرض النص الذي تمت قراءته أعلى الصورة. \r\n",
        "\r\n",
        "## عرض المربعات المحيطة\r\n",
        "\r\n",
        "تتضمن النتائج أيضًا إحداثيات *المربع المحيط *لأسطر النص، والكلمات الفردية الموجودة في الصورة. قم بتشغيل الخلية أدناه لرؤية المربعات المحيطة لأسطر النص في صورة الإعلان التي قمت باستردادها أعلاه."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# افتح الصورة لعرضها.\r\n",
        "fig = plt.figure(figsize=(7, 7))\n",
        "img = Image.open(image_path)\n",
        "draw = ImageDraw.Draw(img)\n",
        "\n",
        "# معالجة النص سطرًا بسطرٍ\r\n",
        "for region in read_results.regions:\n",
        "    for line in region.lines:\n",
        "\n",
        "        # Show the position of the line of text\n",
        "        l,t,w,h = list(map(int, line.bounding_box.split(',')))\n",
        "        draw.rectangle(((l,t), (l+w, t+h)), outline='magenta', width=5)\n",
        "\n",
        "        # Read the words in the line of text\n",
        "        line_text = ''\n",
        "        for word in line.words:\n",
        "            line_text += word.text + ' '\n",
        "        print(line_text.rstrip())\n",
        "\n",
        "# اعرض الصورة مع تحديد مواقع النص\r\n",
        "plt.axis('off')\n",
        "plt.imshow(img)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599694266106
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "في النتيجة، يظهر المربع المحيط لكل سطر من النص كمستطيل على الصورة.\r\n",
        "\r\n",
        "## استخدم Read API\r\n",
        "\r\n",
        "تعمل واجهة برمجة تطبيقات OCR التي استخدمتها سابقًا بشكل جيدٍ مع الصور التي تحتوي على كمية صغيرة من الكتابة النصية. عندما تحتاج إلى قراءة نصوص أكبر حجمًا، مثل المستندات الممسوحة ضوئيًا، يمكنك استخدام **واجهة برمجة التطبيقات للقراءة**. يتطلب هذا عملية متعددة الخطوات:\r\n",
        "\r\n",
        "1. قم بإرسال صورة إلى خدمة الرؤية الخاصة بالكمبيوتر، لتتم قراءتها وتحليلها بشكل غير متزامن.\r\n",
        "2. انتظر حتى تكتمل عملية التحليل.\r\n",
        "3. استرجع نتائج التحليل.\r\n",
        "\r\n",
        "قم بتشغيل الخانة التالية لاستخدام هذه العملية لقراءة النص في رسالة ممسوحة ضوئيًا إلى مدير متجر Northwind Traders."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
        "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
        "from msrest.authentication import CognitiveServicesCredentials\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import time\n",
        "import os\n",
        "%matplotlib inline\n",
        "\n",
        "# اقرأ ملف الصورة\r\n",
        "image_path = os.path.join('data', 'ocr', 'letter.jpg')\n",
        "image_stream = open(image_path, \"rb\")\n",
        "\n",
        "# احصل على عميل لخدمة الرؤية الخاصة بالكمبيوتر\r\n",
        "computervision_client = ComputerVisionClient(cog_endpoint, CognitiveServicesCredentials(cog_key))\n",
        "\n",
        "# أرسل طلبًا لقراءة النص المطبوع في الصورة والحصول على معرف العملية\r\n",
        "read_operation = computervision_client.read_in_stream(image_stream,\n",
        "                                                      raw=True)\n",
        "operation_location = read_operation.headers[\"Operation-Location\"]\n",
        "operation_id = operation_location.split(\"/\")[-1]\n",
        "\n",
        "# انتظر حتى تكتمل العملية غير المتزامنة\r\n",
        "while True:\n",
        "    read_results = computervision_client.get_read_result(operation_id)\n",
        "    if read_results.status not in [OperationStatusCodes.running]:\n",
        "        break\n",
        "    time.sleep(1)\n",
        "\n",
        "# إذا كانت العملية ناجحة، قم بمعالجة النص سطراً بسطر\r\n",
        "if read_results.status == OperationStatusCodes.succeeded:\n",
        "    for result in read_results.analyze_result.read_results:\n",
        "        for line in result.lines:\n",
        "            print(line.text)\n",
        "\n",
        "# افتح الصورة واعرضها.\r\n",
        "print('\\n')\n",
        "fig = plt.figure(figsize=(12,12))\n",
        "img = Image.open(image_path)\n",
        "plt.axis('off')\n",
        "plt.imshow(img)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599694312346
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "معاينة النتائج يوجد نسخة كاملة للرسالة، والتي تتكون في الغالب من نصٍ مطبوعٍ بتوقيع خط اليد. تظهر الصورة الأصلية للحرف أسفل نتائج التعرف على الحروف (قد تحتاج إلى النزول أسفل الصفحة لرؤيتها).\r\n",
        "\r\n",
        "## اقرأ النص المكتوب بخط اليد\r\n",
        "\r\n",
        "في المثال السابق، حدد طلب تحليل الصورة وضع التعرف على النص الذي يعمل على تحسين عملية النص *المطبوع*. لاحظ أنه على الرغم من ذلك، فقد تمت قراءة التوقيع بخط اليد.\r\n",
        "\r\n",
        "هذه القدرة على قراءة النص المكتوب بخط اليد مفيدة للغاية. على سبيل المثال، لنفترض أنك كتبت ملاحظة تحتوي على قائمة تسوق، وتريد استخدام تطبيق على هاتفك لقراءة الملاحظة وتدوين النص الذي تحتوي عليه.\r\n",
        "\r\n",
        "قم بتشغيل الخلية أدناه لمشاهدة مثال لعملية القراءة لقائمة تسوق مكتوبة بخط اليد."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
        "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
        "from msrest.authentication import CognitiveServicesCredentials\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import time\n",
        "import os\n",
        "%matplotlib inline\n",
        "\n",
        "# اقرأ ملف الصورة\r\n",
        "image_path = os.path.join('data', 'ocr', 'note.jpg')\n",
        "image_stream = open(image_path, \"rb\")\n",
        "\n",
        "# احصل على عميل لخدمة الرؤية الخاصة بالكمبيوتر\r\n",
        "computervision_client = ComputerVisionClient(cog_endpoint, CognitiveServicesCredentials(cog_key))\n",
        "\n",
        "# أرسل طلبًا لقراءة النص المطبوع في الصورة والحصول على معرف العملية\r\n",
        "read_operation = computervision_client.read_in_stream(image_stream,\n",
        "                                                      raw=True)\n",
        "operation_location = read_operation.headers[\"Operation-Location\"]\n",
        "operation_id = operation_location.split(\"/\")[-1]\n",
        "\n",
        "# انتظر حتى تكتمل العملية غير المتزامنة\r\n",
        "while True:\n",
        "    read_results = computervision_client.get_read_result(operation_id)\n",
        "    if read_results.status not in [OperationStatusCodes.running]:\n",
        "        break\n",
        "    time.sleep(1)\n",
        "\n",
        "# إذا كانت العملية ناجحة، قم بمعالجة النص سطرًا بسطر\r\n",
        "if read_results.status == OperationStatusCodes.succeeded:\n",
        "    for result in read_results.analyze_result.read_results:\n",
        "        for line in result.lines:\n",
        "            print(line.text)\n",
        "\n",
        "# افتح الصورة واعرضها.\r\n",
        "print('\\n')\n",
        "fig = plt.figure(figsize=(12,12))\n",
        "img = Image.open(image_path)\n",
        "plt.axis('off')\n",
        "plt.imshow(img)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599694340593
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## المزيد من المعلومات\r\n",
        "\r\n",
        "لمزيد من المعلومات حول استخدام خدمة الرؤية الخاصة بالكمبيوتر للتعرف على الحروف OCR، قم بمراجعة [مستندات الرؤية الحاسوبية](https://docs.microsoft.com/ar-sa/azure/cognitive-services/computer-vision/concept-recognizing-text)"
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}