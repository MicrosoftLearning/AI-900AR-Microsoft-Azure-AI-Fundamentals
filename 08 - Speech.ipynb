{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# الكلام\r\n",
        "\r\n",
        "نتوقع أن نكون قادرين بشكل متزايد على التواصل مع أنظمة الذكاء الاصطناعي (AI) من خلال التحدث إليها، غالبًا مع توقع استجابة منطوقة.\r\n",
        "\r\n",
        "![روبوت يتحدث!](./images/speech.jpg)\r\n",
        "\r\n",
        "يعد* التعرف على الكلام* (نظام ذكاء اصطناعي يفسر اللغة المنطوقة) و*اصطناع الكلام *(نظام ذكاء اصطناعي يولد استجابة منطوقة) من المكونات الأساسية لحل الذكاء الاصطناعي الذي يدعم الكلام.\r\n",
        "\r\n",
        "## إنشاء مورد خدمات معرفية\r\n",
        "\r\n",
        "لإنشاء برنامج يمكنه تفسير الكلام المسموع والاستجابة لفظيًا، يمكنك استخدام الخدمة المعرفية **للكلام**، والتي توفر طريقة بسيطة لتحويل اللغة المنطوقة إلى نص والعكس صحيح.\r\n",
        "\r\n",
        "إذا لم يكن لديك واحد بالفعل، فاستخدم الخطوات التالية لإنشاء مورد **خدمات معرفية**في اشتراكك في Azure:\r\n",
        "\r\n",
        "> **ملاحظة**: إذا كان لديك بالفعل مورد خدمات معرفية، فقط افتح صفحة** البدء السريع** الخاصة به في مدخل Azure وانسخ مفتاحه ونقطة النهاية إلى الخانة أدناه. خلاف ذلك، اتبع الخطوات أدناه لإنشاء واحدة.\r\n",
        "\r\n",
        "1. في علامة تبويب مستعرض أخرى، افتح مدخل Azure على https://portal.azure.com، وقم بتسجيل الدخول باستخدام حساب Microsoft الخاص بك.\r\n",
        "2. انقر فوق **&#65291;زر إنشاء مورد** وابحث عن *الخدمات المعرفية*، وأنشئ مورد **خدمات معرفية** بالإعدادات التالية:\r\n",
        "    - **الاشتراك**: *اشتراكك في Azure.*\r\n",
        "    - **مجموعة الموارد**: *حدد أو أنشئ مجموعة موارد باسم فريد*.\r\n",
        "    - **المنطقة** *اختر أي منطقة متوفرة:*\r\n",
        "    - **الاسم:** *أدخل اسمًا فريدًا*.\r\n",
        "    - **مستوى الأسعار**: S0\r\n",
        "    - **أؤكد أنني قد قرأت وفهمت الإخطارات**: تم الاختيار.\r\n",
        "3. انتظر حتى اكتمال النشر. ثم انتقل إلى مورد الخدمات المعرفية الخاص بك، وفي صفحة **نظرة عامة**، انقر على رابط لإدارة مفاتيح الخدمة. ستحتاج إلى المفاتيح والموقع للاتصال بمورد الخدمات المعرفية من تطبيقات العميل.\r\n",
        "\r\n",
        "### احصل على المفتاح والموقع لمورد الخدمات المعرفية\r\n",
        "\r\n",
        "لاستخدام مورد الخدمات المعرفية، تحتاج تطبيقات العميل إلى مفتاح المصادقة والموقع:\r\n",
        "\r\n",
        "1. في مدخل Azure، في صفحة **المفاتيح ونقطة النهاية** لمورد الخدمة المعرفية، انسخ **Key1** لموردك وقم بلصقه في الرمز أدناه، مع استبدال **YOUR_COG_KEY**.\r\n",
        "2. انسخ **الموقع** لموردك والصقه في الرمز أدناه، مع استبدال**YOUR_COG_LOCATION**.\r\n",
        ">**ملاحظة**: ابق في صفحة **المفاتيح ونقطة النهاية** وانسخ **الموقع** من هذه الصفحة (مثال: _westus_). يرجى عدم إضافة مسافات بين الكلمات في حقل الموقع. \r\n",
        "3. قم بتشغيل الرمز أدناه عن طريق النقر فوق الزر **تشغيل الخانة** (&#9655;) الموجود على يسار الخانة."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "cog_key = 'YOUR_COG_KEY'\n",
        "cog_location = 'YOUR_COG_LOCATION'\n",
        "\n",
        "print('Ready to use cognitive services in {} using key {}'.format(cog_location, cog_key))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599695240794
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## التعرف على الكلام\r\n",
        "\r\n",
        "لنفترض أنك تريد إنشاء نظام آلية المنزل يقبل التعليمات المنطوقة، مثل \"تشغيل الوضع الليلي\" أو \"إيقاف تشغيل الوضع الليلي\". يجب أن يكون التطبيق الخاص بك قادرًا على أخذ المدخلات الصوتية (التعليمات المنطوقة الخاصة بك)، وتفسيرها عن طريق نسخها إلى نص يمكنه بعد ذلك تفكيكها وتحليلها.\r\n",
        "\r\n",
        "أنت الآن جاهز لتدوين بعض الكلام. يمكن أن يكون الإدخال من **ميكروفون** أو **ملف صوتي**. \r\n",
        "\r\n",
        "### التعرف على الكلام بواسطة ميكروفون\r\n",
        "\r\n",
        "لنجرب إدخال ميكروفون أولًا. قم بتشغيل الخانة أدناه وقل **على الفور** بصوت عالٍ \"**تشغيل الوضع الليلي\".** استعمل إمكانيات تحويل الكلام إلى نص في خدمة الكلام على نسخ الصوت. يجب أن يكون الإخراج كلامك في الكتابة.\r\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import IPython\n",
        "from azure.cognitiveservices.speech import SpeechConfig, SpeechRecognizer, AudioConfig\n",
        "\n",
        "# تكوين أداة التعرف على الكلام\r\n",
        "speech_config = SpeechConfig(cog_key, cog_location)\n",
        "\n",
        "# اطلب من الطلاب أن يقولوا \"تشغيل الوضع الليلي\" \r\n",
        "speech_recognizer = SpeechRecognizer(speech_config)\n",
        "\n",
        "# استخدم مكالمة متزامنة لمرة واحدة لكتابة الكلام\r\n",
        "speech = speech_recognizer.recognize_once()\n",
        "\n",
        "print(speech.text)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599695250434
        }
      }
    },
    {
      "source": [
        "### (!) تسجيل الوصول\r\n",
        "\r\n",
        "هل تمكنت من تشغيل الخانة وتحويل كلامك إلى نص؟ إذا كانت الخلية أعلاه لا تعطي إخراجًا نصيًا (مثال الإخراج: _ قم بتشغيل الوضع الليلي. _)، حاول تشغيل الخانة مرة أخرى وقل **على الفور** بصوت عالٍ \"تشغيل الوضع الليلي\".\r\n",
        "\r\n",
        "### التعرف على الكلام مع ملف صوتي\r\n",
        "\r\n",
        "إذا لم تقدم الخلية أعلاه إخراجًا نصيًا، فقد يكون الميكروفون غير معدٍ لقبول الإدخال. بدلًا من ذلك، قم بتشغيل الخلية أدناه لمشاهدة خدمة التعرف على الكلام تُجري **بملف صوتي** بدلًا من **إدخال الميكروفون**. \r\n"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from playsound import playsound\n",
        "from azure.cognitiveservices.speech import SpeechConfig, SpeechRecognizer, AudioConfig\n",
        "\n",
        "# الحصول على أمر منطوق من ملف صوتي\r\n",
        "file_name = 'light-on.wav'\n",
        "audio_file = os.path.join('data', 'speech', file_name)\n",
        "\n",
        "# تكوين أداة التعرف على الكلام\r\n",
        "speech_config = SpeechConfig(cog_key, cog_location)\n",
        "audio_config = AudioConfig(filename=audio_file) # Use file instead of default (microphone)\n",
        "speech_recognizer = SpeechRecognizer(speech_config, audio_config)\n",
        "\n",
        "# استخدم مكالمة متزامنة لمرة واحدة لكتابة الكلام\r\n",
        "speech = speech_recognizer.recognize_once()\n",
        "\n",
        "# تشغيل الصوت وإظهار النص المكتوب\r\n",
        "playsound(audio_file)\n",
        "print(speech.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## اصطناع الكلام\r\n",
        "\r\n",
        "لقد رأيت الآن كيف يمكن استخدام خدمة الكلام لتحويل الكلام إلى نص؛ لكن ماذا عن العكس؟ كيف تحوّل نصًا إلى كلام؟\r\n",
        "\r\n",
        "حسنًا، لنفترض أن نظام التشغيل الآلي لمنزلك قد فهم أمرًا لتشغيل الوضع الليلي. قد تكون الاستجابة المناسبة هي الاعتراف بالأمر شفهيًا (بالإضافة إلى تنفيذ المهمة الموصوفة بالفعل!)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from azure.cognitiveservices.speech import SpeechConfig, SpeechSynthesizer, AudioConfig\n",
        "%matplotlib inline\n",
        "\n",
        "# احصل على نص ليتم نطقه\r\n",
        "response_text = 'Turning the light on.'\n",
        "\n",
        "# تكوين تركيب الكلام\r\n",
        "speech_config = SpeechConfig(cog_key, cog_location)\n",
        "speech_synthesizer = SpeechSynthesizer(speech_config)\n",
        "\n",
        "# تحويل النص إلى كلام\r\n",
        "result = speech_synthesizer.speak_text(response_text)\n",
        "\n",
        "# اعرض الصورة المناسبة \r\n",
        "file_name = response_text + \"jpg\"\n",
        "img = Image.open(os.path.join(\"data\", \"speech\", file_name))\n",
        "plt.axis('off')\n",
        "plt. imshow(img)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599695261170
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "حاول تغيير متغير **response_text ** إلى *إيقاف تشغيل الوضع الليلي*. (بما في ذلك النقطة في النهاية) وتشغيل الخانة مرة أخرى لسماع النتيجة.\r\n",
        "\r\n",
        "## معرفة المزيد\r\n",
        "\r\n",
        "لقد رأيت مثالًا بسيطًا جدًا لاستخدام خدمة الكلام المعرفي في هذا الدفتر. يمكنك معرفة المزيد حول تحويل [الكلام إلى نص](https://docs.microsoft.com/azure/cognitive-services/speech-service/index-speech-to-text) وتحويل[ النص إلى كلام](https://docs.microsoft.com/azure/cognitive-services/speech-service/index-text-to-speech) في مستندات خدمة الكلام."
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.8.5-final",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.5 32-bit",
      "metadata": {
        "interpreter": {
          "hash": "177429bd1865e7f7a0dbecbac90518c0d9641b1102b2e6c0df4b82dc948b5cb2"
        }
      }
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}